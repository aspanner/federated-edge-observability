---
# Source: portworx/templates/storageclass/rbac/serviceAccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: portworx-sc-sa
  namespace: portworx
  annotations:
    argocd.argoproj.io/sync-hook: "PreSync"
    argocd.argoproj.io/sync-wave: "-10"
---
# Source: portworx/templates/storageclass/portworx-rwx.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  annotations:
    argocd.argoproj.io/sync-wave: "4"
  name: px-csi-db-shared
parameters:
  io_profile: db_remote
  repl: "3"
  sharedv4: "true"
  sharedv4_svc_type: "ClusterIP"
provisioner: pxd.portworx.com
reclaimPolicy: Delete
volumeBindingMode: Immediate
allowVolumeExpansion: true
---
# Source: portworx/templates/storageclass/rbac/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-wave: "-15"
  name: portworx-sc-clusterrole
rules:
- apiGroups: ["*"]
  resources: ['pods','storageclusters']
  verbs: ['get','list']
---
# Source: portworx/templates/storageclass/rbac/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: portworx-sc-clusterrolebinding
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-wave: "-15"
subjects:
- kind: ServiceAccount
  name: portworx-sc-sa
  namespace: portworx
  apiGroup: ""
roleRef:
  kind: ClusterRole
  name: portworx-sc-clusterrole
  apiGroup: rbac.authorization.k8s.io
---
# Source: portworx/templates/storageclass/rbac/role-ns.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-wave: "-15"
  namespace: portworx 
  name: portworx-sc-ns-role
rules:
- apiGroups: ["*"]
  resources: ["*"]
  verbs: ["*"]
---
# Source: portworx/templates/storageclass/rbac/rolebinding-ns.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: portworx-sc-ns-rolebinding
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-wave: "-15"
subjects:
- kind: ServiceAccount
  name: portworx-sc-sa
  namespace: portworx
  apiGroup: ""
roleRef:
  kind: Role
  name: portworx-sc-ns-role
  apiGroup: rbac.authorization.k8s.io
---
# Source: portworx/templates/storageclass/wait-for-pxe.yaml
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    argocd.argoproj.io/sync-wave: "3"
  name: job-wait-for-portworx
  namespace: portworx
spec:
  template:
    spec:
      containers:
      - image: quay.io/hybridcloudpatterns/utility-container
        command:
        - /bin/bash
        - -x
        - -c
        - |
          stc_status=$(oc get stc -n portworx | grep -E "Online|Running" | wc -l)
          until [ "$stc_status" -eq "1" ];
          do
            echo "Portworx storagecluster not yet online"
            sleep 10
            stc_status=$(oc get stc -n portworx | grep -E "Online|Running" | wc -l)
          done
          echo "Portworx storagecluster online, waiting for all containers to start"
          num_px_pods=$(oc get pod -l name=portworx -n portworx --no-headers | wc -l)
          while [ 1 ];
          do
            num_px_pods_ready=$(oc get pod -l name=portworx -n portworx |grep -P '\s+([1-9]+[\d]*)\/\1\s+' | wc -l)
            if [ "$num_px_pods_ready" -eq "$num_px_pods" ]; then
              echo "Portworx is ready, $num_px_pods_ready of $num_px_pods pods running 2/2"
              exit 0
            fi
            echo "Portworx is not yet ready, $num_px_pods_ready of $num_px_pods pods running 2/2"
            sleep 15
          done
        name: wait-for-portworx-ready
      dnsPolicy: ClusterFirst
      restartPolicy: Never
      serviceAccount: portworx-sc-sa
      serviceAccountName: portworx-sc-sa
      terminationGracePeriodSeconds: 600
---
# Source: portworx/templates/portworx-storagecluster.yaml
apiVersion: core.libopenstorage.org/v1
kind: StorageCluster
metadata:
  name: px-cluster-region
  namespace: portworx
  annotations:
    argocd.argoproj.io/sync-wave: "3"
    portworx.io/is-openshift: "true"
    portworx.com/install-source: helm-rhmcgo
    portworx.com/helm-vars: chart="portworx-0.0.1",cloudProvider="map[storageClass:default-rwo]" ,clusterGroup="map[applications:map[acm:map[ignoreDifferences:[map[group:internal.open-cluster-management.io jsonPointers:[/spec/loggingCA] kind:ManagedClusterInfo]] name:acm namespace:open-cluster-management path:common/acm project:datacenter] odh:map[name:odh namespace:manuela-ml-workspace path:charts/datacenter/opendatahub project:datacenter] pipelines:map[name:pipelines namespace:manuela-ci path:charts/datacenter/pipelines project:datacenter] production-data-lake:map[ignoreDifferences:[map[group:apps jsonPointers:[/spec/replicas] kind:Deployment] map[group:route.openshift.io jsonPointers:[/status] kind:Route] map[group:image.openshift.io jsonPointers:[/spec/tags] kind:ImageStream] map[group:apps.openshift.io jsonPointers:[/spec/template/spec/containers/0/image] kind:DeploymentConfig]] name:production-data-lake namespace:manuela-data-lake path:charts/datacenter/manuela-data-lake project:production-datalake] secrets:map[name:external-secrets namespace:external-secrets path:charts/datacenter/external-secrets project:golang-external-secrets] secrets-operator:map[name:golang-external-secrets namespace:golang-external-secrets path:common/golang-external-secrets project:golang-external-secrets] test:map[name:manuela-test namespace:manuela-tst-all path:charts/datacenter/manuela-tst plugin:map[name:helm-with-kustomize] project:datacenter] vault:map[chart:vault name:vault namespace:vault overrides:[map[name:global.openshift value:true] map[name:injector.enabled value:false] map[name:ui.enabled value:true] map[name:ui.serviceType value:LoadBalancer] map[name:server.route.enabled value:true] map[name:server.route.host value:<nil>] map[name:server.route.tls.termination value:edge] map[name:server.image.repository value:registry.connect.redhat.com/hashicorp/vault] map[name:server.image.tag value:1.10.3-ubi]] project:datacenter repoURL:https://helm.releases.hashicorp.com targetRevision:v0.20.1]] imperative:map[jobs:[map[name:test playbook:ansible/test.yml]]] isHubCluster:true managedClusterGroups:map[factory:map[clusterSelector:map[matchExpressions:[map[key:vendor operator:In values:[OpenShift]]] matchLabels:map[clusterGroup:factory]] helmOverrides:[map[name:clusterGroup.isHubCluster value:false]] name:factory]] name:datacenter namespaces:[golang-external-secrets external-secrets open-cluster-management manuela-ml-workspace manuela-tst-all manuela-ci manuela-data-lake staging vault] operatorgroupExcludes:[manuela-ml-workspace] projects:[datacenter production-datalake golang-external-secrets vault] subscriptions:map[acm:map[channel:release-2.6 name:advanced-cluster-management namespace:open-cluster-management] amqbroker-prod:map[channel:7.x name:amq-broker-rhel8 namespace:manuela-tst-all] amqstreams-prod-dev:map[channel:stable name:amq-streams namespaces:[manuela-data-lake manuela-tst-all]] camelk-prod-dev:map[channel:stable name:red-hat-camel-k namespaces:[manuela-data-lake manuela-tst-all]] odh:map[channel:stable name:opendatahub-operator source:community-operators] pipelines:map[channel:latest name:openshift-pipelines-operator-rh source:redhat-operators] seldon-prod-dev:map[channel:stable name:seldon-operator namespaces:[manuela-ml-workspace manuela-tst-all] source:community-operators]]]" ,csi="true" ,deleteStrategy="UninstallAndWipe" ,envVars="none" ,global="map[clusterDomain:region.example.com clusterPlatform:aws clusterVersion:4.12 hub:map[provider:aws storageClassName:gp2] hubClusterDomain:apps.hub.example.com localClusterDomain:apps.region.example.com namespace:pattern-namespace options:map[installPlanApproval:Automatic syncPolicy:Automatic useCSV:false] pattern:mypattern repoURL:https://github.com/pattern-clone/mypattern]" ,internalKVDB="true" ,main="map[clusterGroupName:hub git:map[repoURL:https://github.com/pattern-clone/mypattern revision:main]]" ,namespace="portworx" ,network="map[dataInterface:none managementInterface:none]" ,pxnamespace="portworx" ,repo="map[dr:docker.io/portworx enterprise:docker.io/portworx]" ,secretType="k8s" ,storage="map[drives:type=gp2,size=20 journalDevice:<nil> kvdbDrives:type=gp2,size=150 maxStorageNodesPerZone:1 usedrivesAndPartitions:false usefileSystemDrive:false]" ,versions="map[autoPilot:1.3.7 enterprise:2.13.4 ociMon:2.13.4 stork:23.4.0]" 
spec:
  deleteStrategy:
    type: UninstallAndWipe
  env:
    # TODO: Change this hardcoded image path to an ECR registry path with px-enterprise image (PWX-27961)
    - name: PX_IMAGE
      value: docker.io/portworx/px-enterprise:2.13.0
    - name: PX_NAMESPACE
      value: portworx
  image: "portworx/oci-monitor:2.13.4"
  imagePullPolicy: Always
  kvdb:
    internal: true
  cloudStorage:
    deviceSpecs:
    - type=gp2,size=20
    journalDeviceSpec: auto
    kvdbDeviceSpec: type=gp2,size=150
    maxStorageNodesPerZone: 1
  secretsProvider: k8s
  stork:
    enabled: true
    args:
      webhook-controller: "true"
    image: "openstorage/stork:23.4.0"
  autopilot:
    enabled: true
    image: "portworx/autopilot:1.3.7"
  csi:
    enabled: true
